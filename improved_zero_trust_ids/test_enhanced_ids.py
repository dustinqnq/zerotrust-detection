#!/usr/bin/env python3
"""
å¢å¼ºé›¶ä¿¡ä»»IDSæµ‹è¯•è„šæœ¬
åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶è¿›è¡Œæ¨ç†æµ‹è¯•
"""

import sys
import os
sys.path.append('../src')

import numpy as np
import pandas as pd
import torch
from enhanced_autoencoder_ids import EnhancedZeroTrustIDS
from processors.iot23_processor import IoT23Processor
import time
import json

def load_test_data():
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    print("=== åŠ è½½æµ‹è¯•æ•°æ® ===")
    
    processor = IoT23Processor()
    data_path = "../data/iot23/CTU-IoT-Malware-Capture-3-1"
    
    try:
        df = processor.load_data(data_path)
        df_processed = processor.preprocess(df)
        features = processor.extract_features(df_processed)
        labels = processor.prepare_labels(df_processed)
        
        # å–ä¸€å°éƒ¨åˆ†æ•°æ®è¿›è¡Œå¿«é€Ÿæµ‹è¯•
        test_size = min(1000, len(features))
        features_test = features[:test_size]
        labels_test = labels[:test_size]
        
        print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {features_test.shape}")
        return features_test, labels_test, df_processed[:test_size]
        
    except Exception as e:
        print(f"æµ‹è¯•æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None, None, None

def test_model_performance():
    """æµ‹è¯•æ¨¡å‹æ€§èƒ½"""
    print("ğŸ§ª å¢å¼ºé›¶ä¿¡ä»»IDSæ¨¡å‹æµ‹è¯•")
    print("=" * 50)
    
    # 1. åŠ è½½æµ‹è¯•æ•°æ®
    features, labels, df = load_test_data()
    if features is None:
        print("âŒ æ— æ³•åŠ è½½æµ‹è¯•æ•°æ®")
        return
    
    # 2. åˆå§‹åŒ–æ¨¡å‹
    print("=== åˆå§‹åŒ–æ¨¡å‹ ===")
    input_dim = features.shape[1]
    model = EnhancedZeroTrustIDS(input_dim=input_dim)
    
    # 3. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    print("=== åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ ===")
    try:
        model.load_models()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ train_enhanced_ids.py")
        return
    
    # 4. æ•°æ®é¢„å¤„ç†
    print("=== æ•°æ®é¢„å¤„ç† ===")
    features_scaled = model.scaler.transform(features)
    
    # 5. æ€§èƒ½æµ‹è¯•
    print("=== æ€§èƒ½æµ‹è¯• ===")
    
    # å•æ ·æœ¬æ¨ç†æ—¶é—´æµ‹è¯•
    print("ğŸ“Š å•æ ·æœ¬æ¨ç†æ—¶é—´æµ‹è¯•:")
    sample = features_scaled[0:1]  # å–ä¸€ä¸ªæ ·æœ¬
    
    # é¢„çƒ­
    for _ in range(10):
        _ = model.predict(sample)
    
    # æ­£å¼æµ‹è¯•
    start_time = time.time()
    for _ in range(100):
        results = model.predict(sample)
    end_time = time.time()
    
    avg_time = (end_time - start_time) / 100 * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
    print(f"å¹³å‡å•æ ·æœ¬æ¨ç†æ—¶é—´: {avg_time:.2f} ms")
    
    # æ‰¹é‡æ¨ç†æµ‹è¯•
    print("\nğŸ“Š æ‰¹é‡æ¨ç†æµ‹è¯•:")
    batch_sizes = [10, 50, 100, 500]
    
    for batch_size in batch_sizes:
        if batch_size <= len(features_scaled):
            batch_data = features_scaled[:batch_size]
            
            start_time = time.time()
            batch_results = model.predict(batch_data)
            end_time = time.time()
            
            total_time = (end_time - start_time) * 1000  # ms
            per_sample_time = total_time / batch_size
            throughput = 1000 / per_sample_time  # samples/second
            
            print(f"æ‰¹é‡å¤§å° {batch_size}: æ€»æ—¶é—´ {total_time:.2f}ms, "
                  f"æ¯æ ·æœ¬ {per_sample_time:.2f}ms, ååé‡ {throughput:.1f} samples/s")
    
    # 6. æ£€æµ‹èƒ½åŠ›æµ‹è¯•
    print("\n=== æ£€æµ‹èƒ½åŠ›æµ‹è¯• ===")
    test_samples = min(200, len(features_scaled))
    test_features = features_scaled[:test_samples]
    test_labels = labels[:test_samples]
    
    predictions = model.predict(test_features)
    
    # ç»Ÿè®¡å„é˜¶æ®µæ£€æµ‹ç»“æœ
    stage_stats = {'stage1': 0, 'stage2': 0, 'stage3': 0}
    detection_stats = {
        'known_attack_stage1': 0,
        'known_attack_stage2': 0, 
        'unknown_attack': 0,
        'benign': 0
    }
    
    confidence_scores = []
    
    for pred in predictions:
        stage_stats[f"stage{pred['stage']}"] += 1
        detection_stats[pred['prediction']] += 1
        confidence_scores.append(pred['confidence'])
    
    print("å„é˜¶æ®µæ£€æµ‹ç»Ÿè®¡:")
    for stage, count in stage_stats.items():
        print(f"{stage}: {count} ({count/len(predictions)*100:.1f}%)")
    
    print("\næ£€æµ‹ç±»å‹ç»Ÿè®¡:")
    for det_type, count in detection_stats.items():
        print(f"{det_type}: {count} ({count/len(predictions)*100:.1f}%)")
    
    print(f"\nå¹³å‡ç½®ä¿¡åº¦: {np.mean(confidence_scores):.3f}")
    print(f"ç½®ä¿¡åº¦æ ‡å‡†å·®: {np.std(confidence_scores):.3f}")
    
    # 7. è¯¦ç»†åˆ†æå‡ ä¸ªæ ·æœ¬
    print("\n=== æ ·æœ¬è¯¦ç»†åˆ†æ ===")
    analyze_samples = min(5, len(predictions))
    
    for i in range(analyze_samples):
        pred = predictions[i]
        actual_label = test_labels[i]
        
        print(f"\næ ·æœ¬ {i+1}:")
        print(f"  å®é™…æ ‡ç­¾: {actual_label}")
        print(f"  é¢„æµ‹ç»“æœ: {pred['prediction']}")
        print(f"  æ£€æµ‹é˜¶æ®µ: Stage {pred['stage']}")
        print(f"  ç½®ä¿¡åº¦: {pred['confidence']:.3f}")
        
        if 'reconstruction_error' in pred:
            print(f"  é‡æ„è¯¯å·®: {pred['reconstruction_error']:.6f}")
            print(f"  å¼‚å¸¸é˜ˆå€¼: {model.anomaly_threshold:.6f}")
    
    # 8. ä¿å­˜æµ‹è¯•ç»“æœ
    print("\n=== ä¿å­˜æµ‹è¯•ç»“æœ ===")
    
    test_results = {
        'performance': {
            'avg_inference_time_ms': avg_time,
            'avg_confidence': float(np.mean(confidence_scores)),
            'confidence_std': float(np.std(confidence_scores))
        },
        'stage_distribution': stage_stats,
        'detection_distribution': detection_stats,
        'sample_predictions': predictions[:10]  # ä¿å­˜å‰10ä¸ªé¢„æµ‹ç»“æœ
    }
    
    with open('improved_zero_trust_ids/test_results.json', 'w') as f:
        json.dump(test_results, f, indent=2, default=str)
    
    print("âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: improved_zero_trust_ids/test_results.json")
    
    return test_results

def real_time_monitoring_demo():
    """å®æ—¶ç›‘æ§æ¼”ç¤º"""
    print("\nğŸ”´ å®æ—¶ç›‘æ§æ¼”ç¤º")
    print("=" * 30)
    
    # åŠ è½½æ¨¡å‹
    features, _, _ = load_test_data()
    if features is None:
        return
    
    input_dim = features.shape[1]
    model = EnhancedZeroTrustIDS(input_dim=input_dim)
    
    try:
        model.load_models()
    except:
        print("âŒ æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
        return
    
    features_scaled = model.scaler.transform(features)
    
    print("å¼€å§‹æ¨¡æ‹Ÿå®æ—¶ç›‘æ§... (æŒ‰Ctrl+Cåœæ­¢)")
    print("æ˜¾ç¤ºæ ¼å¼: [æ—¶é—´] æ ·æœ¬ID | æ£€æµ‹ç»“æœ | é˜¶æ®µ | ç½®ä¿¡åº¦")
    print("-" * 80)
    
    try:
        for i in range(min(50, len(features_scaled))):  # æ¨¡æ‹Ÿ50ä¸ªæ ·æœ¬
            sample = features_scaled[i:i+1]
            
            start_time = time.time()
            result = model.predict(sample)[0]
            end_time = time.time()
            
            # æ ¼å¼åŒ–è¾“å‡º
            timestamp = time.strftime("%H:%M:%S")
            sample_id = f"Sample_{i+1:03d}"
            prediction = result['prediction']
            stage = f"Stage_{result['stage']}"
            confidence = f"{result['confidence']:.3f}"
            inference_time = f"{(end_time-start_time)*1000:.1f}ms"
            
            # æ ¹æ®æ£€æµ‹ç»“æœä½¿ç”¨ä¸åŒé¢œè‰²ï¼ˆç®€å•çš„æ ‡è®°ï¼‰
            if prediction == 'benign':
                status = "âœ… BENIGN    "
            elif 'known_attack' in prediction:
                status = "âš ï¸  KNOWN_ATK "
            else:
                status = "ğŸš¨ UNKNOWN_ATK"
            
            print(f"[{timestamp}] {sample_id} | {status} | {stage} | {confidence} | {inference_time}")
            
            # æ¨¡æ‹Ÿå®æ—¶å»¶è¿Ÿ
            time.sleep(0.1)
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç›‘æ§æ¼”ç¤ºå·²åœæ­¢")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # è¿è¡Œæ€§èƒ½æµ‹è¯•
        test_results = test_model_performance()
        
        if test_results:
            print("\n" + "="*50)
            print("ğŸ“‹ æµ‹è¯•æ€»ç»“:")
            print(f"å¹³å‡æ¨ç†æ—¶é—´: {test_results['performance']['avg_inference_time_ms']:.2f} ms")
            print(f"å¹³å‡ç½®ä¿¡åº¦: {test_results['performance']['avg_confidence']:.3f}")
            
            # è¯¢é—®æ˜¯å¦è¿è¡Œå®æ—¶ç›‘æ§æ¼”ç¤º
            print("\næ˜¯å¦è¿è¡Œå®æ—¶ç›‘æ§æ¼”ç¤º? (y/n): ", end="")
            choice = input().lower().strip()
            
            if choice in ['y', 'yes']:
                real_time_monitoring_demo()
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 
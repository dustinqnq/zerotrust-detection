# 增强大规模数据集配置 (当前使用)

## 概述
本文档记录了将零信任IoT入侵检测系统调整为**增强大规模数据集**训练的配置。在原大规模配置基础上适度扩大，在性能和资源消耗间取得更好平衡。

## 🚀 当前增强大规模配置

### 1. 数据采样策略

#### 每文件处理行数
- **当前配置**: 每个文件处理200,000行 (相比之前的100,000行增加了一倍)
- **影响**: 更充分的数据利用率，适合中高配置主机

#### 进度报告频率
- **当前配置**: 每20,000行报告一次进度
- **影响**: 减少日志输出，提高处理效率

### 2. 攻击类型采样数量

#### 增强大规模分层采样策略
```
当前增强大规模配置:
≥3000个样本: 采样3000个 (↑ 从2000个)
≥1500个样本: 采样1500个 (↑ 从1000个)
≥800个样本: 采样800个 (↑ 从500个)
≥200个样本: 采样200个 (↑ 从100个)
≥100个样本: 采样100个
≥50个样本: 全部使用
<50个样本: 过采样到100个 (↑ 从50个)
```

#### 预期数据集规模
- **当前配置**: 总样本数 40,000-100,000 (增加了一倍规模)
- **相比原始配置**: 40-100倍增长
- **适合硬件**: 24-48GB内存主机

### 3. 良性样本采样策略

#### 平衡策略
- **当前配置**: 良性样本最多8,000个，与恶意样本保持75:100比例
- **优势**: 更接近真实网络环境的流量分布

### 4. 训练参数配置

#### 训练轮数
```
当前增强大规模配置:
阶段1 (浅层分类器): 60轮 (↑ 从50轮)
阶段2 (深层分类器): 60轮 (↑ 从50轮)
阶段3 (自编码器): 120轮 (↑ 从100轮)
```

#### 早停策略
- **早停耐心值**: 20轮 (↑ 从15轮)
- **优势**: 给模型更多时间收敛，获得更好性能

## 🔄 可升级到超大规模配置

如果你的硬件配置更强，可以考虑升级到超大规模配置：

## 🚀 最新超大规模配置

### 1. 数据采样策略超大规模扩展

#### 每文件处理行数大幅增加
- **大规模配置**: 每个文件处理100,000行
- **超大规模配置**: 每个文件处理500,000行 (5倍再增长)
- **影响**: 单文件数据利用率提升到极致

#### 进度报告频率优化
- **大规模配置**: 每10,000行报告一次进度
- **超大规模配置**: 每50,000行报告一次进度
- **影响**: 大幅减少日志输出，专注处理性能

### 2. 攻击类型采样数量超大规模扩展

#### 超大规模分层采样策略
```
大规模配置 → 超大规模配置
≥2000个样本: 采样2000个 → ≥5000个样本: 采样5000个
≥1000个样本: 采样1000个 → ≥3000个样本: 采样3000个
≥500个样本: 采样500个   → ≥2000个样本: 采样2000个
≥100个样本: 采样100个   → ≥1000个样本: 采样1000个
≥50个样本: 全部使用     → ≥500个样本: 采样500个
<50个样本: 过采样到50个  → ≥100个样本: 采样100个
                        → ≥50个样本: 全部使用
                        → <50个样本: 过采样到100个
```

#### 预期数据集规模对比
- **小规模原配置**: 总样本数 ~1,000
- **大规模配置**: 总样本数 20,000-50,000
- **超大规模配置**: 总样本数 50,000-150,000
- **增长倍数**: 50-150倍（相比原始配置）

### 3. 良性样本采样策略进一步优化

#### 平衡策略调整
- **大规模配置**: 良性样本最多5,000个，与恶意样本保持4:5比例
- **超大规模配置**: 良性样本最多10,000个，与恶意样本保持7:10比例
- **优势**: 更加真实的网络流量分布

### 4. 训练参数超大规模优化

#### 训练轮数大幅增加
```
大规模配置 → 超大规模配置
阶段1 (浅层分类器): 50轮 → 80轮
阶段2 (深层分类器): 50轮 → 80轮  
阶段3 (自编码器): 100轮 → 150轮
```

#### 早停策略优化
- **早停耐心值**: 15轮 → 25轮
- **优势**: 给模型更多时间在大数据集上收敛

## 预期效果对比

### 数据集质量提升
1. **攻击类型多样性**: 
   - 大规模: 15-20种攻击变种
   - 超大规模: 25-30种攻击变种
2. **样本数量**: 
   - 大规模: 20,000-50,000
   - 超大规模: 50,000-150,000  
3. **数据覆盖度**: 更全面的攻击模式覆盖

### 模型性能预期
1. **第二阶段检测率**: 预期从10.4%提升到20-35%
2. **整体精确度**: 预期保持在95%+
3. **泛化能力**: 显著提升，能处理更复杂的攻击变种
4. **鲁棒性**: 对未知攻击的检测能力大幅提升

### 训练资源需求
1. **数据加载**: 增加10-25倍时间
2. **训练时间**: 增加25-50倍时间  
3. **内存需求**: 通过批次训练控制，但建议32GB+
4. **存储需求**: 建议200GB+可用空间

## 硬件要求 (当前增强大规模配置)

### 最低配置 (增强大规模)
- **内存**: 24GB RAM (↑ 从16GB)
- **存储**: 150GB可用空间 (↑ 从100GB)
- **GPU**: 推荐，至少GTX 1660
- **CPU**: 10核心以上 (↑ 从8核心)

### 推荐配置 (增强大规模)
- **内存**: 48GB RAM (↑ 从32GB)
- **存储**: 300GB+ SSD (↑ 从200GB)
- **GPU**: NVIDIA RTX 3070或更高 (↑ 从3060)
- **CPU**: 16核心以上，如AMD Ryzen 9或Intel i9

### 理想配置 (增强大规模)
- **内存**: 64GB+ RAM
- **存储**: 500GB+ NVMe SSD
- **GPU**: NVIDIA RTX 4070或更高
- **CPU**: 20核心以上

## 训练时间估算 (增强大规模配置)

### 预期训练时间
- **数据加载**: 1-3小时 (↑ 从30分钟-2小时)
- **阶段1训练**: 2-6小时 (↑ 从1-4小时)
- **阶段2训练**: 3-8小时 (↑ 从2-6小时)
- **阶段3训练**: 4-12小时 (↑ 从2-8小时)
- **总训练时间**: 10-30小时 (↑ 从5-20小时)

## 使用方法

运行大规模训练：
```bash
cd improved_zero_trust_ids
# 直接运行或后台运行
python train_enhanced_ids.py
# 或者后台运行
nohup python train_enhanced_ids.py > training.log 2>&1 &
# 监控进度
tail -f training.log
```

## 性能监控建议

### 关键监控指标
- **内存使用率**: 建议不超过80%
- **GPU利用率**: 建议保持在70%+
- **存储I/O**: 监控读写速度
- **训练收敛**: 观察损失函数变化

## 预期效果 (增强大规模配置)

### 数据集质量提升
1. **攻击类型多样性**: 15-20种攻击变种 (↑ 从10-15种)
2. **样本数量**: 40,000-100,000 (↑ 从20,000-50,000)
3. **数据覆盖度**: 更全面的攻击模式覆盖

### 模型性能预期
1. **第二阶段检测率**: 预期从10.4%提升到20-30% (↑ 从15-25%)
2. **整体精确度**: 预期保持在94%+ (↑ 从92%+)
3. **泛化能力**: 显著提升，能处理更复杂攻击变种
4. **鲁棒性**: 对未知攻击的检测能力大幅提升

### 🎯 性能目标 (增强大规模)
- **第二阶段检测率**: 目标突破25% (↑ 从20%)
- **整体F1分数**: 目标达到94%+ (↑ 从93%+)
- **新型攻击检测**: 显著提升对零日攻击的检测能力
- **误报率**: 保持在4%以下 (↓ 从5%)

## 注意事项

### ⚠️ 重要提醒
1. **训练时间**: 完整训练可能需要10-30小时
2. **资源占用**: 中高强度使用硬件
3. **散热**: 确保良好的散热系统
4. **备份**: 定期保存训练检查点
5. **监控**: 建议监控内存和GPU使用率

### 🔧 优化建议
1. **使用SSD**: 大幅提升数据加载速度
2. **GPU加速**: 强烈推荐，显著提升训练速度
3. **内存充足**: 建议24GB+，避免系统交换
4. **后台运行**: 使用nohup或screen避免中断
5. **定期检查**: 监控训练进度和资源使用

这个增强大规模配置在性能提升和资源消耗间取得了很好的平衡！ 🚀

## 📊 配置对比总结

| 配置类型 | 文件行数 | 最大采样 | 良性样本 | 训练轮数 | 预期样本数 | 预期时间 |
|---------|---------|---------|---------|---------|-----------|----------|
| 原始配置 | 20,000 | 50个 | 500个 | 30轮 | 1,000 | 2-5小时 |
| 大规模配置 | 100,000 | 2,000个 | 5,000个 | 50轮 | 20,000-50,000 | 5-20小时 |
| **增强大规模** | **200,000** | **3,000个** | **8,000个** | **60轮** | **40,000-100,000** | **10-30小时** |
| 超大规模配置 | 500,000 | 5,000个 | 10,000个 | 80轮 | 100,000-150,000 | 20-60小时 |